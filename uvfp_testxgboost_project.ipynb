{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karlychann/neuro140/blob/main/uvfp_testxgboost_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6fffff-5577-40e2-9bd7-b6f88dcc6b7d",
      "metadata": {
        "id": "2b6fffff-5577-40e2-9bd7-b6f88dcc6b7d"
      },
      "source": [
        "# Final models trained on the entire dataset, with and without biased features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ffe31e54-576e-4c25-ab9d-33b7a76adc98",
      "metadata": {
        "id": "ffe31e54-576e-4c25-ab9d-33b7a76adc98"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from io import BytesIO\n",
        "import pickle\n",
        "import requests\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bdab5dfe-b099-4cd2-92b9-1a22ff9f555f",
      "metadata": {
        "id": "bdab5dfe-b099-4cd2-92b9-1a22ff9f555f"
      },
      "outputs": [],
      "source": [
        "all_features = ['F0semitoneFrom27.5Hz_sma3nz_amean',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile20.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope', 'loudness_sma3_amean',\n",
        "       'loudness_sma3_stddevNorm', 'loudness_sma3_percentile20.0',\n",
        "       'loudness_sma3_percentile50.0', 'loudness_sma3_percentile80.0',\n",
        "       'loudness_sma3_pctlrange0-2', 'loudness_sma3_meanRisingSlope',\n",
        "       'loudness_sma3_stddevRisingSlope', 'loudness_sma3_meanFallingSlope',\n",
        "       'loudness_sma3_stddevFallingSlope', 'spectralFlux_sma3_amean',\n",
        "       'spectralFlux_sma3_stddevNorm', 'mfcc1_sma3_amean',\n",
        "       'mfcc1_sma3_stddevNorm', 'mfcc2_sma3_amean', 'mfcc2_sma3_stddevNorm',\n",
        "       'mfcc3_sma3_amean', 'mfcc3_sma3_stddevNorm', 'mfcc4_sma3_amean',\n",
        "       'mfcc4_sma3_stddevNorm', 'jitterLocal_sma3nz_amean',\n",
        "       'jitterLocal_sma3nz_stddevNorm', 'shimmerLocaldB_sma3nz_amean',\n",
        "       'shimmerLocaldB_sma3nz_stddevNorm', 'HNRdBACF_sma3nz_amean',\n",
        "       'HNRdBACF_sma3nz_stddevNorm', 'logRelF0-H1-H2_sma3nz_amean',\n",
        "       'logRelF0-H1-H2_sma3nz_stddevNorm', 'logRelF0-H1-A3_sma3nz_amean',\n",
        "       'logRelF0-H1-A3_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean',\n",
        "       'F1frequency_sma3nz_stddevNorm', 'F1bandwidth_sma3nz_amean',\n",
        "       'F1bandwidth_sma3nz_stddevNorm', 'F1amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F1amplitudeLogRelF0_sma3nz_stddevNorm', 'F2frequency_sma3nz_amean',\n",
        "       'F2frequency_sma3nz_stddevNorm', 'F2bandwidth_sma3nz_amean',\n",
        "       'F2bandwidth_sma3nz_stddevNorm', 'F2amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F2amplitudeLogRelF0_sma3nz_stddevNorm', 'F3frequency_sma3nz_amean',\n",
        "       'F3frequency_sma3nz_stddevNorm', 'F3bandwidth_sma3nz_amean',\n",
        "       'F3bandwidth_sma3nz_stddevNorm', 'F3amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F3amplitudeLogRelF0_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_amean',\n",
        "       'alphaRatioV_sma3nz_stddevNorm', 'hammarbergIndexV_sma3nz_amean',\n",
        "       'hammarbergIndexV_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_amean',\n",
        "       'slopeV0-500_sma3nz_stddevNorm', 'slopeV500-1500_sma3nz_amean',\n",
        "       'slopeV500-1500_sma3nz_stddevNorm', 'spectralFluxV_sma3nz_amean',\n",
        "       'spectralFluxV_sma3nz_stddevNorm', 'mfcc1V_sma3nz_amean',\n",
        "       'mfcc1V_sma3nz_stddevNorm', 'mfcc2V_sma3nz_amean',\n",
        "       'mfcc2V_sma3nz_stddevNorm', 'mfcc3V_sma3nz_amean',\n",
        "       'mfcc3V_sma3nz_stddevNorm', 'mfcc4V_sma3nz_amean',\n",
        "       'mfcc4V_sma3nz_stddevNorm', 'alphaRatioUV_sma3nz_amean',\n",
        "       'hammarbergIndexUV_sma3nz_amean', 'slopeUV0-500_sma3nz_amean',\n",
        "       'slopeUV500-1500_sma3nz_amean', 'spectralFluxUV_sma3nz_amean',\n",
        "       'loudnessPeaksPerSec', 'VoicedSegmentsPerSec',\n",
        "       'MeanVoicedSegmentLengthSec', 'StddevVoicedSegmentLengthSec',\n",
        "       'MeanUnvoicedSegmentLength', 'StddevUnvoicedSegmentLength',\n",
        "       'equivalentSoundLevel_dBp']\n",
        "\n",
        "\n",
        "# from classification_wo_correlated_features.ipynb features that correlate least with biased features\n",
        "uncorrelated_features = ['mfcc4V_sma3nz_amean',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope', 'mfcc1_sma3_amean',\n",
        "       'F3bandwidth_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
        "       'F1frequency_sma3nz_stddevNorm', 'jitterLocal_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
        "       'alphaRatioV_sma3nz_stddevNorm', 'mfcc1_sma3_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope', 'mfcc4_sma3_amean',\n",
        "       'F3frequency_sma3nz_amean', 'mfcc2_sma3_amean',\n",
        "       'VoicedSegmentsPerSec', 'F1bandwidth_sma3nz_amean',\n",
        "       'mfcc2V_sma3nz_amean', 'F3frequency_sma3nz_stddevNorm',\n",
        "       'hammarbergIndexV_sma3nz_stddevNorm',\n",
        "       'logRelF0-H1-H2_sma3nz_amean', 'slopeV500-1500_sma3nz_stddevNorm',\n",
        "       'F2bandwidth_sma3nz_amean', 'mfcc3_sma3_amean',\n",
        "       'F2bandwidth_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_amean',\n",
        "       'mfcc2_sma3_stddevNorm', 'mfcc1V_sma3nz_amean',\n",
        "       'slopeUV0-500_sma3nz_amean', 'mfcc1V_sma3nz_stddevNorm',\n",
        "       'mfcc3V_sma3nz_amean', 'F2frequency_sma3nz_amean',\n",
        "       'logRelF0-H1-A3_sma3nz_amean', 'hammarbergIndexV_sma3nz_amean',\n",
        "       'F1bandwidth_sma3nz_stddevNorm', 'mfcc3_sma3_stddevNorm',\n",
        "       'mfcc2V_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean',\n",
        "       'F2frequency_sma3nz_stddevNorm',\n",
        "       'logRelF0-H1-H2_sma3nz_stddevNorm', 'mfcc4V_sma3nz_stddevNorm',\n",
        "       'mfcc4_sma3_stddevNorm', 'F3bandwidth_sma3nz_amean',\n",
        "       'mfcc3V_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_stddevNorm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bd09080-1cb7-4a02-a352-8b95ee142994",
      "metadata": {
        "id": "6bd09080-1cb7-4a02-a352-8b95ee142994"
      },
      "outputs": [],
      "source": [
        "# load pretrained model\n",
        "# model_name = 'less-biased'\n",
        "# training_model_name = 'rf'\n",
        "# task = 'speech'\n",
        "# feature_set = uncorrelated_features\n",
        "\n",
        "# url_path = f'https://github.com/danielmlow/vfp/blob/main/data/output/{training_model_name}_{model_name}_{task}.pkl?raw=true' # speech models trained on reading task\n",
        "# mfile = BytesIO(requests.get(url_path).content) # load from url\n",
        "# model = pickle.load(mfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2c52bca-dde8-497d-9c06-ce3af579da85",
      "metadata": {
        "id": "c2c52bca-dde8-497d-9c06-ce3af579da85"
      },
      "source": [
        "# Extracting features on your own wav files using egemaps\n",
        "\n",
        "To test on your own data, the test set should match our features (egemaps) using the the same variables and sampling rate (16k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a32bd722-ac4c-43c2-a9c4-feaee136c125",
      "metadata": {
        "id": "a32bd722-ac4c-43c2-a9c4-feaee136c125"
      },
      "outputs": [],
      "source": [
        "# from os.path import exists\n",
        "# # config: depends whether you're on Google Colab or local\n",
        "\n",
        "\n",
        "# # Get URL from github csv by clicking on Download > Copy Link Address\n",
        "\n",
        "# load_from_google_drive = False\n",
        "\n",
        "# if load_from_google_drive:\n",
        "#       # On google colab\n",
        "#       # Mount GDrive and attach it to the colab for data I/O\n",
        "#     from google.colab import drive\n",
        "#     drive.mount('/content/drive')\n",
        "#     input_dir = '/content/drive/My Drive/datum/vfp/data/input/'\n",
        "#     output_dir = '/content/drive/My Drive/datum/vfp/data/output/'\n",
        "#     os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# else:\n",
        "#   # If using jupyter-lab or jupyter notebook, load locally:\n",
        "#   input_dir = './data/input/'\n",
        "#   output_dir = './data/output/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "jJmYwuj1Ekr5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJmYwuj1Ekr5",
        "outputId": "9f2cfd4e-1d40-44f2-f523-8c2deb9abddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "input_dir = '/content/drive/My Drive/neuro140/vfp/data/input/'\n",
        "output_dir = '/content/drive/My Drive/neuro140/vfp/data/output/'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wld07JB9MhuR",
      "metadata": {
        "id": "Wld07JB9MhuR"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/drive/MyDrive/neuro140/vfp/data/archive.zip -d /content/drive/MyDrive/neuro140/vfp/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9BXTHCCWPWGF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BXTHCCWPWGF",
        "outputId": "b4e57a9b-49b5-4e0e-97f5-6a8aec15195e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice087-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice093-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice112-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice136-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice170-info.txt:Diagnosis:\thyperkinetic dysphonia (Vocal fold paralysis)\n"
          ]
        }
      ],
      "source": [
        "! grep 'Vocal fold paralysis' /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gHYlN_G6RqJU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHYlN_G6RqJU",
        "outputId": "8db25ff6-eb62-4f3b-c669-94a2d44b2a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice002-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice019-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice024-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice025-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice032-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice034-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice040-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice045-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice049-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice051-info.txt:Diagnosis:\thealthy\r\n"
          ]
        }
      ],
      "source": [
        "# ! grep 'healthy' /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.txt | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OFd3Ye6LNTUi",
      "metadata": {
        "id": "OFd3Ye6LNTUi"
      },
      "outputs": [],
      "source": [
        "#pip install wfdb scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m6PXTqMpNNx5",
      "metadata": {
        "id": "m6PXTqMpNNx5"
      },
      "outputs": [],
      "source": [
        "# import wfdb\n",
        "# from scipy.io.wavfile import write\n",
        "\n",
        "# def wfdb_to_wav(input_path, output_path, channel=0):\n",
        "#     \"\"\"\n",
        "#     Convert a WFDB file to a WAV file.\n",
        "\n",
        "#     Parameters:\n",
        "#     - input_path: Path to the input WFDB file.\n",
        "#     - output_path: Path to the output WAV file.\n",
        "#     - channel: The channel of the WFDB file to convert (default is 0)\n",
        "#     \"\"\"\n",
        "#     # Read the WFDB file\n",
        "#     record = wfdb.rdrecord(input_path)\n",
        "\n",
        "#     # Extract the signal from the specified channel\n",
        "#     signal = record.p_signal[:, channel]\n",
        "\n",
        "#     # Normalize the signal to be in the range of int16 (required for WAV files)\n",
        "#     signal_normalized = ((signal - signal.min()) / (signal.max() - signal.min()) * (2**15 - 1) - 2**15).astype('int16')\n",
        "\n",
        "#     # Write the normalized signal to a WAV file\n",
        "#     # Note: The sample rate is set according to the WFDB record's sampling frequency\n",
        "#     write(output_path, record.fs, signal_normalized)\n",
        "\n",
        "\n",
        "# new_data = ['voice087', 'voice093', 'voice112', 'voice136', 'voice170',\n",
        "#             'voice002', 'voice019', 'voice024', 'voice025', 'voice032']\n",
        "# for input in new_data:\n",
        "#   wfdb_to_wav(f'/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/{input}'\n",
        "#               , f'/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/{input}.wav')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uToQqMMpV9iw",
      "metadata": {
        "id": "uToQqMMpV9iw"
      },
      "outputs": [],
      "source": [
        "# ! rm /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice001.wav\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4gv4AP-yVVic",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gv4AP-yVVic",
        "outputId": "a5a86640-301d-4f30-d544-9b7ddf98ba7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice002.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice019.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice024.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice025.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice032.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice087.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice093.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice112.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice136.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice170.wav\n"
          ]
        }
      ],
      "source": [
        "! ls /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a161eda-f652-4fa1-a77c-e895c48dfd74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a161eda-f652-4fa1-a77c-e895c48dfd74",
        "outputId": "dbb7840d-0d2f-4221-e806-ec707d8c494d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/996.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/996.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/996.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m952.3/996.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.2/996.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# !pip install -q opensmile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec9f65c-9a42-4494-bf00-75165e06273e",
      "metadata": {
        "id": "fec9f65c-9a42-4494-bf00-75165e06273e"
      },
      "outputs": [],
      "source": [
        "# import glob\n",
        "# import opensmile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c357706f-f776-467a-b665-ecf4b068e78b",
      "metadata": {
        "id": "c357706f-f776-467a-b665-ecf4b068e78b"
      },
      "outputs": [],
      "source": [
        "# wav_dir = '/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.wav'\n",
        "# wav_paths = glob.glob(wav_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f82a7b-60b3-4f6a-a093-e38b0145f4a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83f82a7b-60b3-4f6a-a093-e38b0145f4a6",
        "outputId": "752c5c62-c5c0-4955-90d2-4fdd027b5991"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "# smile = opensmile.Smile(\n",
        "#             feature_set=opensmile.FeatureSet.eGeMAPSv02, #or path to conf: 'gemaps/eGeMAPSv02.conf'\n",
        "#             feature_level=opensmile.FeatureLevel.Functionals,\n",
        "#             sampling_rate=16000,\n",
        "#             resample=True,\n",
        "#             # num_workers = 4,\n",
        "#             verbose=True,\n",
        "#         )\n",
        "# feature_vectors = smile.process_files(wav_paths)\n",
        "# df_voiced = feature_vectors.reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O2QjjUJq0fW_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2QjjUJq0fW_",
        "outputId": "0357e59b-442d-4339-9a2a-6e5d97b6da76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/extracted_voiced.csv\n"
          ]
        }
      ],
      "source": [
        "! find '/content/drive/MyDrive/neuro140/vfp/data/' -name '*.csv**'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3VRsHlKN02g0",
      "metadata": {
        "id": "3VRsHlKN02g0"
      },
      "outputs": [],
      "source": [
        "df_voiced = pd.read_csv('/content/drive/MyDrive/neuro140/vfp/data/extracted_voiced.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d3de98-07dd-40dc-b643-7d7e54e704db",
      "metadata": {
        "id": "25d3de98-07dd-40dc-b643-7d7e54e704db"
      },
      "source": [
        "# Training these models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec295ce-d4b7-48e5-939e-0cd3a9e9e14b",
      "metadata": {
        "id": "eec295ce-d4b7-48e5-939e-0cd3a9e9e14b"
      },
      "outputs": [],
      "source": [
        "# We choose Random Forest as it tends to have highest median classification across analyses\n",
        "# model = RandomForestClassifier(n_estimators= 100)\n",
        "\n",
        "# Others:\n",
        "# LogisticRegressionCV(solver='liblinear', penalty = 'l1', max_iter = 100)\n",
        "# MLPClassifier(alpha = 1, max_iter= 1000)\n",
        "# SGDClassifier(loss='log', penalty=\"elasticnet\", early_stopping=True, max_iter = 5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yw_WsR0C2v51",
      "metadata": {
        "id": "Yw_WsR0C2v51"
      },
      "source": [
        "# XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1DByJK8v20UQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DByJK8v20UQ",
        "outputId": "9bd1f776-9080-40bd-a8a6-1db4a621da69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5-Fold CV ROC AUC Scores for speech - biased - xgboost: [0.94865865 0.93293247 0.92962963 0.91016548 0.89598109]\n",
            "Mean CV ROC AUC for speech - biased - xgboost : 0.9234734642135198\n",
            "Completed training and saving for speech - biased - xgboostwith mean CV ROC AUC: 0.9234734642135198\n",
            "5-Fold CV ROC AUC Scores for speech - less-biased - xgboost: [0.88482886 0.83718779 0.87546296 0.9248227  0.88652482]\n",
            "Mean CV ROC AUC for speech - less-biased - xgboost : 0.8817654263884606\n",
            "Completed training and saving for speech - less-biased - xgboostwith mean CV ROC AUC: 0.8817654263884606\n",
            "5-Fold CV ROC AUC Scores for vowel - biased - xgboost: [0.9705314  0.86183575 0.88309179 0.88599034 0.89651838]\n",
            "Mean CV ROC AUC for vowel - biased - xgboost : 0.8995935301208198\n",
            "Completed training and saving for vowel - biased - xgboostwith mean CV ROC AUC: 0.8995935301208198\n",
            "5-Fold CV ROC AUC Scores for vowel - less-biased - xgboost: [0.95555556 0.8705314  0.88454106 0.84347826 0.84526112]\n",
            "Mean CV ROC AUC for vowel - less-biased - xgboost : 0.8798734804100207\n",
            "Completed training and saving for vowel - less-biased - xgboostwith mean CV ROC AUC: 0.8798734804100207\n"
          ]
        }
      ],
      "source": [
        "training_model_name = 'xgboost'\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Assume df_voiced, all_features, uncorrelated_features, and output_dir are defined elsewhere\n",
        "\n",
        "for task in ['speech', 'vowel']:\n",
        "    df = pd.read_csv(f'https://github.com/danielmlow/vfp/raw/main/data/input/features/egemaps_vector_{task}_cpp.csv', index_col=0)\n",
        "\n",
        "    if task == 'speech':\n",
        "        df = pd.concat([df, df_voiced])  # Assuming df_voiced is defined elsewhere\n",
        "\n",
        "    for feature_set, model_name in zip([all_features, uncorrelated_features],  # Assuming these are defined\n",
        "                                       ['biased', 'less-biased']):\n",
        "\n",
        "        X = df[feature_set].values\n",
        "        y = df['target'].values\n",
        "\n",
        "        # Define the model\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # Adjust parameters as necessary\n",
        "\n",
        "        # Initialize StratifiedKFold to maintain the target distribution within each fold\n",
        "        cv = StratifiedKFold(n_splits=5)\n",
        "\n",
        "        # Perform 5-fold cross-validation and compute the ROC AUC score for each fold\n",
        "        # Note: It's important to use a metric suitable for your problem, here we assume binary classification\n",
        "        cv_scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n",
        "\n",
        "        # Print out the mean cross-validation score\n",
        "        print(f'5-Fold CV ROC AUC Scores for {task} - {model_name} - {training_model_name}:', cv_scores)\n",
        "        print(f'Mean CV ROC AUC for {task} - {model_name} - {training_model_name} :', cv_scores.mean())\n",
        "\n",
        "        # You might still want to train and save the final model on the entire dataset\n",
        "        model.fit(X, y)  # Train the model on the entire dataset\n",
        "\n",
        "        # Save the trained model\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(model, f)\n",
        "\n",
        "        # Optional: Load model example (commented)\n",
        "        # with open(output_path, 'rb') as f:\n",
        "        #     model = pickle.load(f)\n",
        "\n",
        "        # Since we're now using cross-validation, the performance metric printed here would be from CV\n",
        "        print(f'Completed training and saving for {task} - {model_name} - {training_model_name}with mean CV ROC AUC: {cv_scores.mean()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HezayJriClxr",
      "metadata": {
        "id": "HezayJriClxr"
      },
      "source": [
        "# Tested to hyperparameter tune using the below code and save into file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35NBnK1J-eRD",
      "metadata": {
        "id": "35NBnK1J-eRD"
      },
      "outputs": [],
      "source": [
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# for reproducibility, I added random seed\n",
        "random_seed = 42\n",
        "\n",
        "# Updated hyperparameter grid\n",
        "param_grid = {\n",
        "    # 'n_estimators': [50, 100, 200],\n",
        "    # 'max_depth': [3, 6, 9],\n",
        "    # 'learning_rate': [0.01, 0.1, 0.2],\n",
        "    # 'min_child_weight': [1, 3, 5],\n",
        "    # 'subsample': [0.6, 0.8, 1.0],\n",
        "    # 'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "for task in ['speech', 'vowel']:\n",
        "    df = pd.read_csv(f'https://github.com/danielmlow/vfp/raw/main/data/input/features/egemaps_vector_{task}_cpp.csv', index_col=0)\n",
        "    if task == 'speech':\n",
        "        df = pd.concat([df, df_voiced])  # Assuming df_voiced is defined elsewhere\n",
        "\n",
        "    for feature_set, model_name in zip([all_features, uncorrelated_features],  # Assuming these are defined\n",
        "                                       ['biased', 'less-biased']):\n",
        "        X = df[feature_set].values\n",
        "        y = df['target'].values\n",
        "\n",
        "        # Initialize the classifier\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_seed)\n",
        "\n",
        "        # Initialize StratifiedKFold\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
        "\n",
        "        # Set up GridSearchCV\n",
        "        grid_search = GridSearchCV(model, param_grid, scoring='roc_auc', cv=cv, verbose=1, n_jobs=-1)\n",
        "        grid_search.fit(X, y)\n",
        "\n",
        "        # Best model after grid search\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Print out the best parameters and mean cross-validation score\n",
        "        print(f'Best parameters for {task} - {model_name}:', grid_search.best_params_)\n",
        "        print(f'Best CV score for {task} - {model_name}:', grid_search.best_score_)\n",
        "\n",
        "        # Save the trained model\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertuned.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(best_model, f)\n",
        "\n",
        "        # Save the best parameters in a file\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertunedparameters.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(grid_search.best_params_, f)\n",
        "\n",
        "        print(f'Model saved for {task} - {model_name} with parameters {grid_search.best_params_}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RzQEh2zmCjNL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzQEh2zmCjNL",
        "outputId": "c057f356-c767-4543-bfde-73aab76d9956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for speech - biased: {'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
            "Best CV score for speech - biased: 0.9582565868366052\n",
            "Model saved for speech - biased with parameters {'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for speech - less-biased: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Best CV score for speech - less-biased: 0.9248676636858877\n",
            "Model saved for speech - less-biased with parameters {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for vowel - biased: {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
            "Best CV score for vowel - biased: 0.9543907156673115\n",
            "Model saved for vowel - biased with parameters {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for vowel - less-biased: {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 0.6}\n",
            "Best CV score for vowel - less-biased: 0.9520684177575944\n",
            "Model saved for vowel - less-biased with parameters {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 0.6}\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# for reproducibility, I added random seed\n",
        "random_seed = 42\n",
        "\n",
        "# Hyperparameter grid XGBoost\n",
        "new_param_grids = {\n",
        "    ('speech', 'biased') : {\n",
        "        'n_estimators': [200],\n",
        "        'max_depth': [9],\n",
        "        'learning_rate': [0.1],\n",
        "        'min_child_weight': [5],\n",
        "        'subsample': [0.8],\n",
        "        'colsample_bytree': [0.6]\n",
        "    },\n",
        "    ('speech', 'less-biased') : {\n",
        "        'n_estimators': [200],\n",
        "        'max_depth': [3],\n",
        "        'learning_rate': [0.2],\n",
        "        'min_child_weight': [1],\n",
        "        'subsample': [1.0],\n",
        "        'colsample_bytree': [1.0]\n",
        "    },\n",
        "    ('vowel', 'biased') : {\n",
        "        'n_estimators': [200],\n",
        "        'max_depth': [9],\n",
        "        'learning_rate': [0.01],\n",
        "        'min_child_weight': [1],\n",
        "        'subsample': [0.6],\n",
        "        'colsample_bytree': [0.6]\n",
        "    },\n",
        "    ('vowel', 'less-biased') : {\n",
        "        'n_estimators': [50],\n",
        "        'max_depth': [3],\n",
        "        'learning_rate': [0.2],\n",
        "        'min_child_weight': [1],\n",
        "        'subsample': [0.6],\n",
        "        'colsample_bytree': [0.6]\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "for task in ['speech', 'vowel']:\n",
        "    df = pd.read_csv(f'https://github.com/danielmlow/vfp/raw/main/data/input/features/egemaps_vector_{task}_cpp.csv', index_col=0)\n",
        "    if task == 'speech':\n",
        "        df = pd.concat([df, df_voiced])  # Assuming df_voiced is defined elsewhere\n",
        "\n",
        "    for feature_set, model_name in zip([all_features, uncorrelated_features],  # Assuming these are defined\n",
        "                                       ['biased', 'less-biased']):\n",
        "        X = df[feature_set].values\n",
        "        y = df['target'].values\n",
        "\n",
        "        # Initialize the classifier\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_seed)\n",
        "\n",
        "        # Initialize StratifiedKFold\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
        "\n",
        "        # Set up GridSearchCV\n",
        "        param_grid = new_param_grids[(task, model_name)]\n",
        "        grid_search = GridSearchCV(model, param_grid, scoring='roc_auc', cv=cv, verbose=1, n_jobs=-1)\n",
        "        grid_search.fit(X, y)\n",
        "\n",
        "        # Best model after grid search\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Print out the best parameters and mean cross-validation score\n",
        "        print(f'Best parameters for {task} - {model_name}:', grid_search.best_params_)\n",
        "        print(f'Best CV score for {task} - {model_name}:', grid_search.best_score_)\n",
        "\n",
        "        # Save the trained model\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertuned2.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(best_model, f)\n",
        "\n",
        "        # Save the best parameters in a file\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertunedparameters2.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(grid_search.best_params_, f)\n",
        "\n",
        "        print(f'Model saved for {task} - {model_name} with parameters {grid_search.best_params_}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "miZCcHCeyq77",
      "metadata": {
        "id": "miZCcHCeyq77"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zTDEjocJyPju",
      "metadata": {
        "id": "zTDEjocJyPju"
      },
      "outputs": [],
      "source": [
        "# Permutation feature importance\n",
        "\n",
        "training_model_name = 'xgboost'\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for task in ['speech', 'vowel']:\n",
        "    df = pd.read_csv(f'https://github.com/danielmlow/vfp/raw/main/data/input/features/egemaps_vector_{task}_cpp.csv', index_col=0)\n",
        "    if task == 'speech':\n",
        "        df = pd.concat([df, df_voiced])  # Assuming df_voiced is defined elsewhere\n",
        "\n",
        "    for feature_set, model_name in zip([all_features, uncorrelated_features],  # Assuming these are defined\n",
        "                                       ['biased', 'less-biased']):\n",
        "        X = df[feature_set].values\n",
        "        y = df['target'].values\n",
        "\n",
        "        # Load the trained model\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertuned2.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'rb') as f:\n",
        "            best_model = pickle.load(f)\n",
        "\n",
        "        result = permutation_importance(best_model, X, y, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "\n",
        "        sorted_idx = result.importances_mean.argsort()\n",
        "        sorted_results = result.importances[sorted_idx]\n",
        "        sorted_results = sorted_results[-10:]\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.boxplot(sorted_results.T,\n",
        "                  vert=False, labels=np.array(feature_set)[sorted_idx][-10:])\n",
        "        ax.set_title(\"Permutation Importance of each feature\")\n",
        "        ax.set_ylabel(\"Features\")\n",
        "        ax.set_xlabel(\"Importance\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93eb3ac4-292c-44bd-b78f-825e82fbce7a",
      "metadata": {
        "id": "93eb3ac4-292c-44bd-b78f-825e82fbce7a"
      },
      "source": [
        "# Other features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c4abe5-1080-4046-b878-d12c67317ee6",
      "metadata": {
        "id": "27c4abe5-1080-4046-b878-d12c67317ee6"
      },
      "outputs": [],
      "source": [
        "cpp_features = ['cpp_amean', 'cpp_stddevNorm', 'cpp_percentile20', 'cpp_percentile80']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}