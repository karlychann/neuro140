{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karlychann/neuro140/blob/main/uvfp_testxgboost_one_dataset_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6fffff-5577-40e2-9bd7-b6f88dcc6b7d",
      "metadata": {
        "id": "2b6fffff-5577-40e2-9bd7-b6f88dcc6b7d"
      },
      "source": [
        "# Final models trained on the entire dataset, with and without biased features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffe31e54-576e-4c25-ab9d-33b7a76adc98",
      "metadata": {
        "id": "ffe31e54-576e-4c25-ab9d-33b7a76adc98"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from io import BytesIO\n",
        "import pickle\n",
        "import requests\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdab5dfe-b099-4cd2-92b9-1a22ff9f555f",
      "metadata": {
        "id": "bdab5dfe-b099-4cd2-92b9-1a22ff9f555f"
      },
      "outputs": [],
      "source": [
        "all_features = ['F0semitoneFrom27.5Hz_sma3nz_amean',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile20.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope', 'loudness_sma3_amean',\n",
        "       'loudness_sma3_stddevNorm', 'loudness_sma3_percentile20.0',\n",
        "       'loudness_sma3_percentile50.0', 'loudness_sma3_percentile80.0',\n",
        "       'loudness_sma3_pctlrange0-2', 'loudness_sma3_meanRisingSlope',\n",
        "       'loudness_sma3_stddevRisingSlope', 'loudness_sma3_meanFallingSlope',\n",
        "       'loudness_sma3_stddevFallingSlope', 'spectralFlux_sma3_amean',\n",
        "       'spectralFlux_sma3_stddevNorm', 'mfcc1_sma3_amean',\n",
        "       'mfcc1_sma3_stddevNorm', 'mfcc2_sma3_amean', 'mfcc2_sma3_stddevNorm',\n",
        "       'mfcc3_sma3_amean', 'mfcc3_sma3_stddevNorm', 'mfcc4_sma3_amean',\n",
        "       'mfcc4_sma3_stddevNorm', 'jitterLocal_sma3nz_amean',\n",
        "       'jitterLocal_sma3nz_stddevNorm', 'shimmerLocaldB_sma3nz_amean',\n",
        "       'shimmerLocaldB_sma3nz_stddevNorm', 'HNRdBACF_sma3nz_amean',\n",
        "       'HNRdBACF_sma3nz_stddevNorm', 'logRelF0-H1-H2_sma3nz_amean',\n",
        "       'logRelF0-H1-H2_sma3nz_stddevNorm', 'logRelF0-H1-A3_sma3nz_amean',\n",
        "       'logRelF0-H1-A3_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean',\n",
        "       'F1frequency_sma3nz_stddevNorm', 'F1bandwidth_sma3nz_amean',\n",
        "       'F1bandwidth_sma3nz_stddevNorm', 'F1amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F1amplitudeLogRelF0_sma3nz_stddevNorm', 'F2frequency_sma3nz_amean',\n",
        "       'F2frequency_sma3nz_stddevNorm', 'F2bandwidth_sma3nz_amean',\n",
        "       'F2bandwidth_sma3nz_stddevNorm', 'F2amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F2amplitudeLogRelF0_sma3nz_stddevNorm', 'F3frequency_sma3nz_amean',\n",
        "       'F3frequency_sma3nz_stddevNorm', 'F3bandwidth_sma3nz_amean',\n",
        "       'F3bandwidth_sma3nz_stddevNorm', 'F3amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F3amplitudeLogRelF0_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_amean',\n",
        "       'alphaRatioV_sma3nz_stddevNorm', 'hammarbergIndexV_sma3nz_amean',\n",
        "       'hammarbergIndexV_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_amean',\n",
        "       'slopeV0-500_sma3nz_stddevNorm', 'slopeV500-1500_sma3nz_amean',\n",
        "       'slopeV500-1500_sma3nz_stddevNorm', 'spectralFluxV_sma3nz_amean',\n",
        "       'spectralFluxV_sma3nz_stddevNorm', 'mfcc1V_sma3nz_amean',\n",
        "       'mfcc1V_sma3nz_stddevNorm', 'mfcc2V_sma3nz_amean',\n",
        "       'mfcc2V_sma3nz_stddevNorm', 'mfcc3V_sma3nz_amean',\n",
        "       'mfcc3V_sma3nz_stddevNorm', 'mfcc4V_sma3nz_amean',\n",
        "       'mfcc4V_sma3nz_stddevNorm', 'alphaRatioUV_sma3nz_amean',\n",
        "       'hammarbergIndexUV_sma3nz_amean', 'slopeUV0-500_sma3nz_amean',\n",
        "       'slopeUV500-1500_sma3nz_amean', 'spectralFluxUV_sma3nz_amean',\n",
        "       'loudnessPeaksPerSec', 'VoicedSegmentsPerSec',\n",
        "       'MeanVoicedSegmentLengthSec', 'StddevVoicedSegmentLengthSec',\n",
        "       'MeanUnvoicedSegmentLength', 'StddevUnvoicedSegmentLength',\n",
        "       'equivalentSoundLevel_dBp']\n",
        "\n",
        "\n",
        "# from classification_wo_correlated_features.ipynb features that correlate least with biased features\n",
        "uncorrelated_features = ['mfcc4V_sma3nz_amean',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope', 'mfcc1_sma3_amean',\n",
        "       'F3bandwidth_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
        "       'F1frequency_sma3nz_stddevNorm', 'jitterLocal_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
        "       'alphaRatioV_sma3nz_stddevNorm', 'mfcc1_sma3_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope', 'mfcc4_sma3_amean',\n",
        "       'F3frequency_sma3nz_amean', 'mfcc2_sma3_amean',\n",
        "       'VoicedSegmentsPerSec', 'F1bandwidth_sma3nz_amean',\n",
        "       'mfcc2V_sma3nz_amean', 'F3frequency_sma3nz_stddevNorm',\n",
        "       'hammarbergIndexV_sma3nz_stddevNorm',\n",
        "       'logRelF0-H1-H2_sma3nz_amean', 'slopeV500-1500_sma3nz_stddevNorm',\n",
        "       'F2bandwidth_sma3nz_amean', 'mfcc3_sma3_amean',\n",
        "       'F2bandwidth_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_amean',\n",
        "       'mfcc2_sma3_stddevNorm', 'mfcc1V_sma3nz_amean',\n",
        "       'slopeUV0-500_sma3nz_amean', 'mfcc1V_sma3nz_stddevNorm',\n",
        "       'mfcc3V_sma3nz_amean', 'F2frequency_sma3nz_amean',\n",
        "       'logRelF0-H1-A3_sma3nz_amean', 'hammarbergIndexV_sma3nz_amean',\n",
        "       'F1bandwidth_sma3nz_stddevNorm', 'mfcc3_sma3_stddevNorm',\n",
        "       'mfcc2V_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean',\n",
        "       'F2frequency_sma3nz_stddevNorm',\n",
        "       'logRelF0-H1-H2_sma3nz_stddevNorm', 'mfcc4V_sma3nz_stddevNorm',\n",
        "       'mfcc4_sma3_stddevNorm', 'F3bandwidth_sma3nz_amean',\n",
        "       'mfcc3V_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_stddevNorm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bd09080-1cb7-4a02-a352-8b95ee142994",
      "metadata": {
        "id": "6bd09080-1cb7-4a02-a352-8b95ee142994"
      },
      "outputs": [],
      "source": [
        "# load pretrained model\n",
        "# model_name = 'less-biased'\n",
        "# training_model_name = 'rf'\n",
        "# task = 'speech'\n",
        "# feature_set = uncorrelated_features\n",
        "\n",
        "# url_path = f'https://github.com/danielmlow/vfp/blob/main/data/output/{training_model_name}_{model_name}_{task}.pkl?raw=true' # speech models trained on reading task\n",
        "# mfile = BytesIO(requests.get(url_path).content) # load from url\n",
        "# model = pickle.load(mfile)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "input_dir = '/content/drive/My Drive/neuro140/vfp/data/input/'\n",
        "output_dir = '/content/drive/My Drive/neuro140/vfp/data/output/'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJmYwuj1Ekr5",
        "outputId": "6315bbe2-14a5-4dce-de38-c8aaa47a98a0"
      },
      "id": "jJmYwuj1Ekr5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/drive/MyDrive/neuro140/vfp/data/archive.zip -d /content/drive/MyDrive/neuro140/vfp/data"
      ],
      "metadata": {
        "id": "Wld07JB9MhuR"
      },
      "id": "Wld07JB9MhuR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! grep 'Vocal fold paralysis' /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BXTHCCWPWGF",
        "outputId": "b4e57a9b-49b5-4e0e-97f5-6a8aec15195e"
      },
      "id": "9BXTHCCWPWGF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice087-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice093-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice112-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice136-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice170-info.txt:Diagnosis:\thyperkinetic dysphonia (Vocal fold paralysis)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! grep 'healthy' /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.txt | head"
      ],
      "metadata": {
        "id": "gHYlN_G6RqJU",
        "outputId": "8db25ff6-eb62-4f3b-c669-94a2d44b2a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gHYlN_G6RqJU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice002-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice019-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice024-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice025-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice032-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice034-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice040-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice045-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice049-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice051-info.txt:Diagnosis:\thealthy\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install wfdb scipy"
      ],
      "metadata": {
        "id": "OFd3Ye6LNTUi"
      },
      "id": "OFd3Ye6LNTUi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import wfdb\n",
        "# from scipy.io.wavfile import write\n",
        "\n",
        "# def wfdb_to_wav(input_path, output_path, channel=0):\n",
        "#     \"\"\"\n",
        "#     Convert a WFDB file to a WAV file.\n",
        "\n",
        "#     Parameters:\n",
        "#     - input_path: Path to the input WFDB file.\n",
        "#     - output_path: Path to the output WAV file.\n",
        "#     - channel: The channel of the WFDB file to convert (default is 0)\n",
        "#     \"\"\"\n",
        "#     # Read the WFDB file\n",
        "#     record = wfdb.rdrecord(input_path)\n",
        "\n",
        "#     # Extract the signal from the specified channel\n",
        "#     signal = record.p_signal[:, channel]\n",
        "\n",
        "#     # Normalize the signal to be in the range of int16 (required for WAV files)\n",
        "#     signal_normalized = ((signal - signal.min()) / (signal.max() - signal.min()) * (2**15 - 1) - 2**15).astype('int16')\n",
        "\n",
        "#     # Write the normalized signal to a WAV file\n",
        "#     # Note: The sample rate is set according to the WFDB record's sampling frequency\n",
        "#     write(output_path, record.fs, signal_normalized)\n",
        "\n",
        "\n",
        "# new_data = ['voice087', 'voice093', 'voice112', 'voice136', 'voice170',\n",
        "#             'voice002', 'voice019', 'voice024', 'voice025', 'voice032']\n",
        "# for input in new_data:\n",
        "#   wfdb_to_wav(f'/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/{input}'\n",
        "#               , f'/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/{input}.wav')\n"
      ],
      "metadata": {
        "id": "m6PXTqMpNNx5"
      },
      "id": "m6PXTqMpNNx5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! rm /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice001.wav\n"
      ],
      "metadata": {
        "id": "uToQqMMpV9iw"
      },
      "id": "uToQqMMpV9iw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.wav"
      ],
      "metadata": {
        "id": "4gv4AP-yVVic",
        "outputId": "a5a86640-301d-4f30-d544-9b7ddf98ba7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4gv4AP-yVVic",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice002.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice019.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice024.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice025.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice032.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice087.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice093.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice112.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice136.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice170.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a161eda-f652-4fa1-a77c-e895c48dfd74",
      "metadata": {
        "id": "8a161eda-f652-4fa1-a77c-e895c48dfd74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb7840d-0d2f-4221-e806-ec707d8c494d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/996.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/996.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/996.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m952.3/996.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.2/996.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# !pip install -q opensmile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec9f65c-9a42-4494-bf00-75165e06273e",
      "metadata": {
        "id": "fec9f65c-9a42-4494-bf00-75165e06273e"
      },
      "outputs": [],
      "source": [
        "# import glob\n",
        "# import opensmile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c357706f-f776-467a-b665-ecf4b068e78b",
      "metadata": {
        "id": "c357706f-f776-467a-b665-ecf4b068e78b"
      },
      "outputs": [],
      "source": [
        "# wav_dir = '/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.wav'\n",
        "# wav_paths = glob.glob(wav_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f82a7b-60b3-4f6a-a093-e38b0145f4a6",
      "metadata": {
        "id": "83f82a7b-60b3-4f6a-a093-e38b0145f4a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752c5c62-c5c0-4955-90d2-4fdd027b5991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ],
      "source": [
        "# smile = opensmile.Smile(\n",
        "#             feature_set=opensmile.FeatureSet.eGeMAPSv02, #or path to conf: 'gemaps/eGeMAPSv02.conf'\n",
        "#             feature_level=opensmile.FeatureLevel.Functionals,\n",
        "#             sampling_rate=16000,\n",
        "#             resample=True,\n",
        "#             # num_workers = 4,\n",
        "#             verbose=True,\n",
        "#         )\n",
        "# feature_vectors = smile.process_files(wav_paths)\n",
        "# df_voiced = feature_vectors.reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! find '/content/drive/MyDrive/neuro140/vfp/data/' -name '*.csv**'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2QjjUJq0fW_",
        "outputId": "0357e59b-442d-4339-9a2a-6e5d97b6da76"
      },
      "id": "O2QjjUJq0fW_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/extracted_voiced.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_voiced = pd.read_csv('/content/drive/MyDrive/neuro140/vfp/data/extracted_voiced.csv')"
      ],
      "metadata": {
        "id": "3VRsHlKN02g0"
      },
      "id": "3VRsHlKN02g0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "25d3de98-07dd-40dc-b643-7d7e54e704db",
      "metadata": {
        "id": "25d3de98-07dd-40dc-b643-7d7e54e704db"
      },
      "source": [
        "# Training these models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec295ce-d4b7-48e5-939e-0cd3a9e9e14b",
      "metadata": {
        "id": "eec295ce-d4b7-48e5-939e-0cd3a9e9e14b"
      },
      "outputs": [],
      "source": [
        "# We choose Random Forest as it tends to have highest median classification across analyses\n",
        "# model = RandomForestClassifier(n_estimators= 100)\n",
        "\n",
        "# Others:\n",
        "# LogisticRegressionCV(solver='liblinear', penalty = 'l1', max_iter = 100)\n",
        "# MLPClassifier(alpha = 1, max_iter= 1000)\n",
        "# SGDClassifier(loss='log', penalty=\"elasticnet\", early_stopping=True, max_iter = 5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost Model (Low Train, VOICED Test)"
      ],
      "metadata": {
        "id": "Yw_WsR0C2v51"
      },
      "id": "Yw_WsR0C2v51"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "random_seed = 42\n",
        "\n",
        "new_param_grids = {\n",
        "    ('speech', 'biased') : {\n",
        "        'n_estimators': [200],\n",
        "        'max_depth': [9],\n",
        "        'learning_rate': [0.1],\n",
        "        'min_child_weight': [5],\n",
        "        'subsample': [0.8],\n",
        "        'colsample_bytree': [0.6]\n",
        "    },\n",
        "    ('speech', 'less-biased') : {\n",
        "        'n_estimators': [200],\n",
        "        'max_depth': [3],\n",
        "        'learning_rate': [0.2],\n",
        "        'min_child_weight': [1],\n",
        "        'subsample': [1.0],\n",
        "        'colsample_bytree': [1.0]\n",
        "    },\n",
        "    ('vowel', 'biased') : {\n",
        "        'n_estimators': [200],\n",
        "        'max_depth': [9],\n",
        "        'learning_rate': [0.01],\n",
        "        'min_child_weight': [1],\n",
        "        'subsample': [0.6],\n",
        "        'colsample_bytree': [0.6]\n",
        "    },\n",
        "    ('vowel', 'less-biased') : {\n",
        "        'n_estimators': [50],\n",
        "        'max_depth': [3],\n",
        "        'learning_rate': [0.2],\n",
        "        'min_child_weight': [1],\n",
        "        'subsample': [0.6],\n",
        "        'colsample_bytree': [0.6]\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "for task in ['speech', 'vowel']:\n",
        "    df = pd.read_csv(f'https://github.com/danielmlow/vfp/raw/main/data/input/features/egemaps_vector_{task}_cpp.csv', index_col=0)\n",
        "\n",
        "    for feature_set, model_name in zip([all_features, uncorrelated_features],\n",
        "                                       ['biased', 'less-biased']):\n",
        "        X = df[feature_set].values\n",
        "        y = df['target'].values\n",
        "\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_seed)\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
        "\n",
        "        param_grid = new_param_grids[(task, model_name)]\n",
        "        grid_search = GridSearchCV(model, param_grid, scoring='roc_auc', cv=cv, verbose=1, n_jobs=-1)\n",
        "        grid_search.fit(X, y)\n",
        "\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        print(f'Best parameters for {task} - {model_name}:', grid_search.best_params_)\n",
        "        print(f'Best CV score for {task} - {model_name}:', grid_search.best_score_)\n",
        "\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertuned2_noVOICED.pkl'\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(best_model, f)\n",
        "\n",
        "        X_test = df_voiced[feature_set].values\n",
        "        y_test = df_voiced['target'].values\n",
        "\n",
        "        y_probs = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        roc_auc = roc_auc_score(y_test, y_probs)\n",
        "        print(f'Low Train, ROC AUC Score: {roc_auc}')\n",
        "\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertunedparameters2_noVOICED.pkl'\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(grid_search.best_params_, f)\n",
        "\n",
        "        print(f'Model saved for {task} - {model_name} with parameters {grid_search.best_params_}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzQEh2zmCjNL",
        "outputId": "7640ade4-e0e6-4fb4-c7eb-a055f43e68a7"
      },
      "id": "RzQEh2zmCjNL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for speech - biased: {'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
            "Best CV score for speech - biased: 0.9590979171922742\n",
            "Low Train, ROC AUC Score: 0.8400000000000001\n",
            "Model saved for speech - biased with parameters {'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for speech - less-biased: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Best CV score for speech - less-biased: 0.9237118175277287\n",
            "Low Train, ROC AUC Score: 0.6400000000000001\n",
            "Model saved for speech - less-biased with parameters {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for vowel - biased: {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
            "Best CV score for vowel - biased: 0.9543907156673115\n",
            "Low Train, ROC AUC Score: 0.92\n",
            "Model saved for vowel - biased with parameters {'colsample_bytree': 0.6, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for vowel - less-biased: {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 0.6}\n",
            "Best CV score for vowel - less-biased: 0.9520684177575944\n",
            "Low Train, ROC AUC Score: 0.7200000000000001\n",
            "Model saved for vowel - less-biased with parameters {'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 0.6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93eb3ac4-292c-44bd-b78f-825e82fbce7a",
      "metadata": {
        "id": "93eb3ac4-292c-44bd-b78f-825e82fbce7a"
      },
      "source": [
        "# Other features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c4abe5-1080-4046-b878-d12c67317ee6",
      "metadata": {
        "id": "27c4abe5-1080-4046-b878-d12c67317ee6"
      },
      "outputs": [],
      "source": [
        "cpp_features = ['cpp_amean', 'cpp_stddevNorm', 'cpp_percentile20', 'cpp_percentile80']"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}