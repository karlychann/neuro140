{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karlychann/neuro140/blob/main/uvfp_testrf_one_dataset_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6fffff-5577-40e2-9bd7-b6f88dcc6b7d",
      "metadata": {
        "id": "2b6fffff-5577-40e2-9bd7-b6f88dcc6b7d"
      },
      "source": [
        "# Final models trained on the entire dataset, with and without biased features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffe31e54-576e-4c25-ab9d-33b7a76adc98",
      "metadata": {
        "id": "ffe31e54-576e-4c25-ab9d-33b7a76adc98"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from io import BytesIO\n",
        "import pickle\n",
        "import requests\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdab5dfe-b099-4cd2-92b9-1a22ff9f555f",
      "metadata": {
        "id": "bdab5dfe-b099-4cd2-92b9-1a22ff9f555f"
      },
      "outputs": [],
      "source": [
        "all_features = ['F0semitoneFrom27.5Hz_sma3nz_amean',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile20.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope', 'loudness_sma3_amean',\n",
        "       'loudness_sma3_stddevNorm', 'loudness_sma3_percentile20.0',\n",
        "       'loudness_sma3_percentile50.0', 'loudness_sma3_percentile80.0',\n",
        "       'loudness_sma3_pctlrange0-2', 'loudness_sma3_meanRisingSlope',\n",
        "       'loudness_sma3_stddevRisingSlope', 'loudness_sma3_meanFallingSlope',\n",
        "       'loudness_sma3_stddevFallingSlope', 'spectralFlux_sma3_amean',\n",
        "       'spectralFlux_sma3_stddevNorm', 'mfcc1_sma3_amean',\n",
        "       'mfcc1_sma3_stddevNorm', 'mfcc2_sma3_amean', 'mfcc2_sma3_stddevNorm',\n",
        "       'mfcc3_sma3_amean', 'mfcc3_sma3_stddevNorm', 'mfcc4_sma3_amean',\n",
        "       'mfcc4_sma3_stddevNorm', 'jitterLocal_sma3nz_amean',\n",
        "       'jitterLocal_sma3nz_stddevNorm', 'shimmerLocaldB_sma3nz_amean',\n",
        "       'shimmerLocaldB_sma3nz_stddevNorm', 'HNRdBACF_sma3nz_amean',\n",
        "       'HNRdBACF_sma3nz_stddevNorm', 'logRelF0-H1-H2_sma3nz_amean',\n",
        "       'logRelF0-H1-H2_sma3nz_stddevNorm', 'logRelF0-H1-A3_sma3nz_amean',\n",
        "       'logRelF0-H1-A3_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean',\n",
        "       'F1frequency_sma3nz_stddevNorm', 'F1bandwidth_sma3nz_amean',\n",
        "       'F1bandwidth_sma3nz_stddevNorm', 'F1amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F1amplitudeLogRelF0_sma3nz_stddevNorm', 'F2frequency_sma3nz_amean',\n",
        "       'F2frequency_sma3nz_stddevNorm', 'F2bandwidth_sma3nz_amean',\n",
        "       'F2bandwidth_sma3nz_stddevNorm', 'F2amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F2amplitudeLogRelF0_sma3nz_stddevNorm', 'F3frequency_sma3nz_amean',\n",
        "       'F3frequency_sma3nz_stddevNorm', 'F3bandwidth_sma3nz_amean',\n",
        "       'F3bandwidth_sma3nz_stddevNorm', 'F3amplitudeLogRelF0_sma3nz_amean',\n",
        "       'F3amplitudeLogRelF0_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_amean',\n",
        "       'alphaRatioV_sma3nz_stddevNorm', 'hammarbergIndexV_sma3nz_amean',\n",
        "       'hammarbergIndexV_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_amean',\n",
        "       'slopeV0-500_sma3nz_stddevNorm', 'slopeV500-1500_sma3nz_amean',\n",
        "       'slopeV500-1500_sma3nz_stddevNorm', 'spectralFluxV_sma3nz_amean',\n",
        "       'spectralFluxV_sma3nz_stddevNorm', 'mfcc1V_sma3nz_amean',\n",
        "       'mfcc1V_sma3nz_stddevNorm', 'mfcc2V_sma3nz_amean',\n",
        "       'mfcc2V_sma3nz_stddevNorm', 'mfcc3V_sma3nz_amean',\n",
        "       'mfcc3V_sma3nz_stddevNorm', 'mfcc4V_sma3nz_amean',\n",
        "       'mfcc4V_sma3nz_stddevNorm', 'alphaRatioUV_sma3nz_amean',\n",
        "       'hammarbergIndexUV_sma3nz_amean', 'slopeUV0-500_sma3nz_amean',\n",
        "       'slopeUV500-1500_sma3nz_amean', 'spectralFluxUV_sma3nz_amean',\n",
        "       'loudnessPeaksPerSec', 'VoicedSegmentsPerSec',\n",
        "       'MeanVoicedSegmentLengthSec', 'StddevVoicedSegmentLengthSec',\n",
        "       'MeanUnvoicedSegmentLength', 'StddevUnvoicedSegmentLength',\n",
        "       'equivalentSoundLevel_dBp']\n",
        "\n",
        "\n",
        "# from classification_wo_correlated_features.ipynb features that correlate least with biased features\n",
        "uncorrelated_features = ['mfcc4V_sma3nz_amean',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope', 'mfcc1_sma3_amean',\n",
        "       'F3bandwidth_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
        "       'F1frequency_sma3nz_stddevNorm', 'jitterLocal_sma3nz_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
        "       'alphaRatioV_sma3nz_stddevNorm', 'mfcc1_sma3_stddevNorm',\n",
        "       'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope', 'mfcc4_sma3_amean',\n",
        "       'F3frequency_sma3nz_amean', 'mfcc2_sma3_amean',\n",
        "       'VoicedSegmentsPerSec', 'F1bandwidth_sma3nz_amean',\n",
        "       'mfcc2V_sma3nz_amean', 'F3frequency_sma3nz_stddevNorm',\n",
        "       'hammarbergIndexV_sma3nz_stddevNorm',\n",
        "       'logRelF0-H1-H2_sma3nz_amean', 'slopeV500-1500_sma3nz_stddevNorm',\n",
        "       'F2bandwidth_sma3nz_amean', 'mfcc3_sma3_amean',\n",
        "       'F2bandwidth_sma3nz_stddevNorm', 'alphaRatioV_sma3nz_amean',\n",
        "       'mfcc2_sma3_stddevNorm', 'mfcc1V_sma3nz_amean',\n",
        "       'slopeUV0-500_sma3nz_amean', 'mfcc1V_sma3nz_stddevNorm',\n",
        "       'mfcc3V_sma3nz_amean', 'F2frequency_sma3nz_amean',\n",
        "       'logRelF0-H1-A3_sma3nz_amean', 'hammarbergIndexV_sma3nz_amean',\n",
        "       'F1bandwidth_sma3nz_stddevNorm', 'mfcc3_sma3_stddevNorm',\n",
        "       'mfcc2V_sma3nz_stddevNorm', 'F1frequency_sma3nz_amean',\n",
        "       'F2frequency_sma3nz_stddevNorm',\n",
        "       'logRelF0-H1-H2_sma3nz_stddevNorm', 'mfcc4V_sma3nz_stddevNorm',\n",
        "       'mfcc4_sma3_stddevNorm', 'F3bandwidth_sma3nz_amean',\n",
        "       'mfcc3V_sma3nz_stddevNorm', 'slopeV0-500_sma3nz_stddevNorm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bd09080-1cb7-4a02-a352-8b95ee142994",
      "metadata": {
        "id": "6bd09080-1cb7-4a02-a352-8b95ee142994"
      },
      "outputs": [],
      "source": [
        "# load pretrained model\n",
        "# model_name = 'less-biased'\n",
        "# training_model_name = 'rf'\n",
        "# task = 'speech'\n",
        "# feature_set = uncorrelated_features\n",
        "\n",
        "# url_path = f'https://github.com/danielmlow/vfp/blob/main/data/output/{training_model_name}_{model_name}_{task}.pkl?raw=true' # speech models trained on reading task\n",
        "# mfile = BytesIO(requests.get(url_path).content) # load from url\n",
        "# model = pickle.load(mfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2c52bca-dde8-497d-9c06-ce3af579da85",
      "metadata": {
        "id": "c2c52bca-dde8-497d-9c06-ce3af579da85"
      },
      "source": [
        "# Extract features on your own wav files using egemaps\n",
        "\n",
        "\n",
        "To test on your own data, the test set should match our features (egemaps) using the the same variables and sampling rate (16k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a32bd722-ac4c-43c2-a9c4-feaee136c125",
      "metadata": {
        "id": "a32bd722-ac4c-43c2-a9c4-feaee136c125"
      },
      "outputs": [],
      "source": [
        "# from os.path import exists\n",
        "# # config: depends whether you're on Google Colab or local\n",
        "\n",
        "\n",
        "# # Get URL from github csv by clicking on Download > Copy Link Address\n",
        "\n",
        "# load_from_google_drive = False\n",
        "\n",
        "# if load_from_google_drive:\n",
        "#       # On google colab\n",
        "#       # Mount GDrive and attach it to the colab for data I/O\n",
        "#     from google.colab import drive\n",
        "#     drive.mount('/content/drive')\n",
        "#     input_dir = '/content/drive/My Drive/datum/vfp/data/input/'\n",
        "#     output_dir = '/content/drive/My Drive/datum/vfp/data/output/'\n",
        "#     os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# else:\n",
        "#   # If using jupyter-lab or jupyter notebook, load locally:\n",
        "#   input_dir = './data/input/'\n",
        "#   output_dir = './data/output/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "input_dir = '/content/drive/My Drive/neuro140/vfp/data/input/'\n",
        "output_dir = '/content/drive/My Drive/neuro140/vfp/data/output/'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJmYwuj1Ekr5",
        "outputId": "b6d1f5aa-8ffc-4313-c2d9-c82681605e70"
      },
      "id": "jJmYwuj1Ekr5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/drive/MyDrive/neuro140/vfp/data/archive.zip -d /content/drive/MyDrive/neuro140/vfp/data"
      ],
      "metadata": {
        "id": "Wld07JB9MhuR"
      },
      "id": "Wld07JB9MhuR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! grep 'Vocal fold paralysis' /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BXTHCCWPWGF",
        "outputId": "b4e57a9b-49b5-4e0e-97f5-6a8aec15195e"
      },
      "id": "9BXTHCCWPWGF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice087-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice093-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice112-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice136-info.txt:Diagnosis:\thypokinetic dysphonia (Vocal fold paralysis)\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice170-info.txt:Diagnosis:\thyperkinetic dysphonia (Vocal fold paralysis)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! grep 'healthy' /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.txt | head"
      ],
      "metadata": {
        "id": "gHYlN_G6RqJU",
        "outputId": "8db25ff6-eb62-4f3b-c669-94a2d44b2a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gHYlN_G6RqJU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice002-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice019-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice024-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice025-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice032-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice034-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice040-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice045-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice049-info.txt:Diagnosis:\thealthy\r\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice051-info.txt:Diagnosis:\thealthy\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install wfdb scipy"
      ],
      "metadata": {
        "id": "OFd3Ye6LNTUi"
      },
      "id": "OFd3Ye6LNTUi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import wfdb\n",
        "# from scipy.io.wavfile import write\n",
        "\n",
        "# def wfdb_to_wav(input_path, output_path, channel=0):\n",
        "#     \"\"\"\n",
        "#     Convert a WFDB file to a WAV file.\n",
        "\n",
        "#     Parameters:\n",
        "#     - input_path: Path to the input WFDB file.\n",
        "#     - output_path: Path to the output WAV file.\n",
        "#     - channel: The channel of the WFDB file to convert (default is 0)\n",
        "#     \"\"\"\n",
        "#     # Read the WFDB file\n",
        "#     record = wfdb.rdrecord(input_path)\n",
        "\n",
        "#     # Extract the signal from the specified channel\n",
        "#     signal = record.p_signal[:, channel]\n",
        "\n",
        "#     # Normalize the signal to be in the range of int16 (required for WAV files)\n",
        "#     signal_normalized = ((signal - signal.min()) / (signal.max() - signal.min()) * (2**15 - 1) - 2**15).astype('int16')\n",
        "\n",
        "#     # Write the normalized signal to a WAV file\n",
        "#     # Note: The sample rate is set according to the WFDB record's sampling frequency\n",
        "#     write(output_path, record.fs, signal_normalized)\n",
        "\n",
        "\n",
        "# new_data = ['voice087', 'voice093', 'voice112', 'voice136', 'voice170',\n",
        "#             'voice002', 'voice019', 'voice024', 'voice025', 'voice032']\n",
        "# for input in new_data:\n",
        "#   wfdb_to_wav(f'/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/{input}'\n",
        "#               , f'/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/{input}.wav')\n"
      ],
      "metadata": {
        "id": "m6PXTqMpNNx5"
      },
      "id": "m6PXTqMpNNx5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! rm /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice001.wav\n"
      ],
      "metadata": {
        "id": "uToQqMMpV9iw"
      },
      "id": "uToQqMMpV9iw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.wav"
      ],
      "metadata": {
        "id": "4gv4AP-yVVic",
        "outputId": "a5a86640-301d-4f30-d544-9b7ddf98ba7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4gv4AP-yVVic",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice002.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice019.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice024.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice025.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice032.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice087.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice093.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice112.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice136.wav\n",
            "/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/voice170.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a161eda-f652-4fa1-a77c-e895c48dfd74",
      "metadata": {
        "id": "8a161eda-f652-4fa1-a77c-e895c48dfd74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb7840d-0d2f-4221-e806-ec707d8c494d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/996.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/996.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/996.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m952.3/996.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.2/996.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# !pip install -q opensmile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec9f65c-9a42-4494-bf00-75165e06273e",
      "metadata": {
        "id": "fec9f65c-9a42-4494-bf00-75165e06273e"
      },
      "outputs": [],
      "source": [
        "# import glob\n",
        "# import opensmile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c357706f-f776-467a-b665-ecf4b068e78b",
      "metadata": {
        "id": "c357706f-f776-467a-b665-ecf4b068e78b"
      },
      "outputs": [],
      "source": [
        "# wav_dir = '/content/drive/MyDrive/neuro140/vfp/data/VOICEDDATASET/*.wav'\n",
        "# wav_paths = glob.glob(wav_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f82a7b-60b3-4f6a-a093-e38b0145f4a6",
      "metadata": {
        "id": "83f82a7b-60b3-4f6a-a093-e38b0145f4a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752c5c62-c5c0-4955-90d2-4fdd027b5991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ],
      "source": [
        "# smile = opensmile.Smile(\n",
        "#             feature_set=opensmile.FeatureSet.eGeMAPSv02, #or path to conf: 'gemaps/eGeMAPSv02.conf'\n",
        "#             feature_level=opensmile.FeatureLevel.Functionals,\n",
        "#             sampling_rate=16000,\n",
        "#             resample=True,\n",
        "#             # num_workers = 4,\n",
        "#             verbose=True,\n",
        "#         )\n",
        "# feature_vectors = smile.process_files(wav_paths)\n",
        "# df_voiced = feature_vectors.reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! find '/content/drive/MyDrive/neuro140/vfp/data/' -name '*.csv**'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2QjjUJq0fW_",
        "outputId": "0357e59b-442d-4339-9a2a-6e5d97b6da76"
      },
      "id": "O2QjjUJq0fW_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/neuro140/vfp/data/extracted_voiced.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_voiced = pd.read_csv('/content/drive/MyDrive/neuro140/vfp/data/extracted_voiced.csv')"
      ],
      "metadata": {
        "id": "3VRsHlKN02g0"
      },
      "id": "3VRsHlKN02g0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "25d3de98-07dd-40dc-b643-7d7e54e704db",
      "metadata": {
        "id": "25d3de98-07dd-40dc-b643-7d7e54e704db"
      },
      "source": [
        "\n",
        "# Training these models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec295ce-d4b7-48e5-939e-0cd3a9e9e14b",
      "metadata": {
        "id": "eec295ce-d4b7-48e5-939e-0cd3a9e9e14b"
      },
      "outputs": [],
      "source": [
        "# We choose Random Forest as it tends to have highest median classification across analyses\n",
        "# model = RandomForestClassifier(n_estimators= 100)\n",
        "\n",
        "# Others:\n",
        "# LogisticRegressionCV(solver='liblinear', penalty = 'l1', max_iter = 100)\n",
        "# MLPClassifier(alpha = 1, max_iter= 1000)\n",
        "# SGDClassifier(loss='log', penalty=\"elasticnet\", early_stopping=True, max_iter = 5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Model"
      ],
      "metadata": {
        "id": "Yw_WsR0C2v51"
      },
      "id": "Yw_WsR0C2v51"
    },
    {
      "cell_type": "code",
      "source": [
        "training_model_name = 'rf'\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Define a random seed for reproducibility\n",
        "random_seed = 38\n",
        "\n",
        "# Assume df_voiced, all_features, uncorrelated_features, and output_dir are defined elsewhere\n",
        "\n",
        "for task in ['speech', 'vowel']:\n",
        "    df = pd.read_csv(f'https://github.com/danielmlow/vfp/raw/main/data/input/features/egemaps_vector_{task}_cpp.csv', index_col=0)\n",
        "\n",
        "    for feature_set, model_name in zip([all_features, uncorrelated_features],  # Assuming these are defined\n",
        "                                       ['biased', 'less-biased']):\n",
        "\n",
        "        X = df[feature_set].values\n",
        "        y = df['target'].values\n",
        "\n",
        "        # Define the model\n",
        "        model = RandomForestClassifier(n_estimators=100, random_state=random_seed)\n",
        "\n",
        "        # Initialize StratifiedKFold to maintain the target distribution within each fold\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
        "\n",
        "        # Perform 5-fold cross-validation and compute the ROC AUC score for each fold\n",
        "        # Note: It's important to use a metric suitable for your problem, here we assume binary classification\n",
        "        cv_scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n",
        "\n",
        "        # Print out the mean cross-validation score\n",
        "        print(f'5-Fold CV ROC AUC Scores for {task} - {model_name} - {training_model_name}:', cv_scores)\n",
        "        print(f'Mean CV ROC AUC for {task} - {model_name} - {training_model_name} :', cv_scores.mean())\n",
        "\n",
        "        # You might still want to train and save the final model on the entire dataset\n",
        "        model.fit(X, y)  # Train the model on the entire dataset\n",
        "\n",
        "        X_test = df_voiced[feature_set].values\n",
        "        y_test = df_voiced['target'].values\n",
        "\n",
        "        # Predict probabilities for the test data\n",
        "        y_probs = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
        "\n",
        "        # Calculate ROC AUC for each class and take the average\n",
        "        roc_auc = roc_auc_score(y_test, y_probs)\n",
        "        print(f'ROC AUC Score: {roc_auc}')\n",
        "\n",
        "        # Save the trained model\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_noVOICED.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(model, f)\n",
        "\n",
        "        # Optional: Load model example (commented)\n",
        "        # with open(output_path, 'rb') as f:\n",
        "        #     model = pickle.load(f)\n",
        "\n",
        "        # Since we're now using cross-validation, the performance metric printed here would be from CV\n",
        "        print(f'Completed training and saving for {task} - {model_name} - {training_model_name}with mean CV ROC AUC: {cv_scores.mean()}')"
      ],
      "metadata": {
        "id": "1DByJK8v20UQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7d9993-5934-4974-fff4-da558cd17079"
      },
      "id": "1DByJK8v20UQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-Fold CV ROC AUC Scores for speech - biased - rf: [0.96835749 0.90072464 0.95647969 0.95701581 0.96195652]\n",
            "Mean CV ROC AUC for speech - biased - rf : 0.9489068296283838\n",
            "ROC AUC Score: 0.04000000000000001\n",
            "Completed training and saving for speech - biased - rfwith mean CV ROC AUC: 0.9489068296283838\n",
            "5-Fold CV ROC AUC Scores for speech - less-biased - rf: [0.92801932 0.89202899 0.9115087  0.90909091 0.92613636]\n",
            "Mean CV ROC AUC for speech - less-biased - rf : 0.9133568571935824\n",
            "ROC AUC Score: 0.9400000000000001\n",
            "Completed training and saving for speech - less-biased - rfwith mean CV ROC AUC: 0.9133568571935824\n",
            "5-Fold CV ROC AUC Scores for vowel - biased - rf: [0.99227053 0.95821256 0.97294686 0.95797101 0.94801741]\n",
            "Mean CV ROC AUC for vowel - biased - rf : 0.9658836748614732\n",
            "ROC AUC Score: 0.8400000000000001\n",
            "Completed training and saving for vowel - biased - rfwith mean CV ROC AUC: 0.9658836748614732\n",
            "5-Fold CV ROC AUC Scores for vowel - less-biased - rf: [0.97294686 0.93743961 0.93719807 0.92826087 0.91658607]\n",
            "Mean CV ROC AUC for vowel - less-biased - rf : 0.9384862968257973\n",
            "ROC AUC Score: 0.36\n",
            "Completed training and saving for vowel - less-biased - rfwith mean CV ROC AUC: 0.9384862968257973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs = model.predict_proba(X_test) # Get probabilities for the positive class\n",
        "y_predict = model.predict(X_test)\n",
        "y_probs[: ,0], y_predict\n",
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FsoducP-d_0",
        "outputId": "4208f928-96ca-44fe-acd2-09f014a58780"
      },
      "id": "7FsoducP-d_0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tested to hyperparameter tune using the below code and save into file"
      ],
      "metadata": {
        "id": "HezayJriClxr"
      },
      "id": "HezayJriClxr"
    },
    {
      "cell_type": "code",
      "source": [
        "training_model_name = 'rf'\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Define a random seed for reproducibility\n",
        "random_seed = 42\n",
        "\n",
        "new_param_grids = {\n",
        "    ('speech', 'biased') : {\n",
        "      'n_estimators': [300],\n",
        "      'max_depth': [None],\n",
        "      'min_samples_split': [5],\n",
        "      'min_samples_leaf': [2],\n",
        "      'max_features': ['auto'],\n",
        "      'bootstrap': [False]\n",
        "    },\n",
        "    ('speech', 'less-biased') : {\n",
        "      'n_estimators': [200],\n",
        "      'max_depth': [None],\n",
        "      'min_samples_split': [2],\n",
        "      'min_samples_leaf': [2],\n",
        "      'max_features': ['sqrt'],\n",
        "      'bootstrap': [True]\n",
        "    },\n",
        "    ('vowel', 'biased') : {\n",
        "      'n_estimators': [100],\n",
        "      'max_depth': [10],\n",
        "      'min_samples_split': [2],\n",
        "      'min_samples_leaf': [1],\n",
        "      'max_features': ['auto'],\n",
        "      'bootstrap': [True]\n",
        "    },\n",
        "    ('vowel', 'less-biased') : {\n",
        "      'n_estimators': [200],\n",
        "      'max_depth': [30],\n",
        "      'min_samples_split': [2],\n",
        "      'min_samples_leaf': [1],\n",
        "      'max_features': ['sqrt'],\n",
        "      'bootstrap': [False]\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "\n",
        "for task in ['speech', 'vowel']:\n",
        "    df = pd.read_csv(f'https://github.com/danielmlow/vfp/raw/main/data/input/features/egemaps_vector_{task}_cpp.csv', index_col=0)\n",
        "\n",
        "    for feature_set, model_name in zip([all_features, uncorrelated_features],  # Assuming these are defined\n",
        "                                       ['biased', 'less-biased']):\n",
        "\n",
        "        # train with Low dataset\n",
        "        X = df[feature_set].values\n",
        "        y = df['target'].values\n",
        "\n",
        "        # Initialize the classifier\n",
        "        model = RandomForestClassifier(n_estimators=100, random_state=random_seed)\n",
        "\n",
        "        # Initialize StratifiedKFold\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
        "\n",
        "        # Set up GridSearchCV\n",
        "        param_grid = new_param_grids[(task, model_name)]\n",
        "        grid_search = GridSearchCV(model, param_grid, scoring='roc_auc', cv=cv, verbose=1, n_jobs=-1)\n",
        "        grid_search.fit(X, y)\n",
        "\n",
        "        # Best model after grid search\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Print out the best parameters and mean cross-validation score\n",
        "        print(f'Best parameters for {task} - {model_name}:', grid_search.best_params_)\n",
        "        print(f'Best CV score for {task} - {model_name}:', grid_search.best_score_)\n",
        "\n",
        "        # Save the trained model\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertuned2_NoVOICED.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(best_model, f)\n",
        "\n",
        "        # test with VOICED dataset\n",
        "        X_test = df_voiced[feature_set].values\n",
        "        y_test = df_voiced['target'].values\n",
        "\n",
        "        # Predict probabilities for the test data\n",
        "        y_probs = best_model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
        "\n",
        "        # Calculate ROC AUC for each class and take the average\n",
        "        roc_auc = roc_auc_score(y_test, y_probs)\n",
        "        print(f'Low Train, ROC AUC Score: {roc_auc}')\n",
        "\n",
        "        # Save the best parameters in a file\n",
        "        output_path = f'{output_dir}{task}_{model_name}_{training_model_name}_hypertunedparameters2_NoVOICED.pkl'  # Assuming output_dir is defined\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(grid_search.best_params_, f)\n",
        "\n",
        "        print(f'Model saved for {task} - {model_name} with parameters {grid_search.best_params_}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35NBnK1J-eRD",
        "outputId": "d98bd653-52d1-461d-e743-99d54647f57a"
      },
      "id": "35NBnK1J-eRD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for speech - biased: {'bootstrap': False, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Best CV score for speech - biased: 0.9540939926555098\n",
            "Low Train, ROC AUC Score: 0.32\n",
            "Model saved for speech - biased with parameters {'bootstrap': False, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for speech - less-biased: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best CV score for speech - less-biased: 0.9107861220904698\n",
            "Low Train, ROC AUC Score: 0.5800000000000001\n",
            "Model saved for speech - less-biased with parameters {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for vowel - biased: {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best CV score for vowel - biased: 0.961635597417281\n",
            "Low Train, ROC AUC Score: 0.6799999999999999\n",
            "Model saved for vowel - biased with parameters {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best parameters for vowel - less-biased: {'bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best CV score for vowel - less-biased: 0.9436122557676674\n",
            "Low Train, ROC AUC Score: 0.5\n",
            "Model saved for vowel - less-biased with parameters {'bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93eb3ac4-292c-44bd-b78f-825e82fbce7a",
      "metadata": {
        "id": "93eb3ac4-292c-44bd-b78f-825e82fbce7a"
      },
      "source": [
        "# Other features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c4abe5-1080-4046-b878-d12c67317ee6",
      "metadata": {
        "id": "27c4abe5-1080-4046-b878-d12c67317ee6"
      },
      "outputs": [],
      "source": [
        "cpp_features = ['cpp_amean', 'cpp_stddevNorm', 'cpp_percentile20', 'cpp_percentile80']"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}